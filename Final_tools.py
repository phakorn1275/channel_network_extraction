# -*- coding: utf-8 -*-
"""Copy of MMDet_seniorproject_v9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RxNQndIpHfnim-_z0sZBjHqImmYM-LPx

# Channel_Extraction

This is result of my senior project!

If you want to get my model to train your data. 

please feel free to get it!

## Install MMDetection
"""

# Check nvcc version
!nvcc -V
# Check GCC version
!gcc --version

# Commented out IPython magic to ensure Python compatibility.
# install dependencies: (use cu101 because colab has CUDA 10.1)
# !pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html
!pip install -U torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html

# install mmcv-full thus we could use CUDA operators
!pip install mmcv-full

# Install mmdetection
!rm -rf mmdetection
!git clone https://github.com/open-mmlab/mmdetection.git
# %cd mmdetection

!pip install -e .

# install Pillow 7.0.0 back in order to avoid bug in colab
!pip install Pillow==7.0.0

# Check Pytorch installation
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())

# Check MMDetection installation
import mmdet
print(mmdet.__version__)

# Check mmcv installation
from mmcv.ops import get_compiling_cuda_version, get_compiler_version
print(get_compiling_cuda_version())
print(get_compiler_version())

"""### Support a new dataset

There are three ways to support a new dataset in MMDetection: 
  1. reorganize the dataset into COCO format.
  2. reorganize the dataset into a middle format.
  3. implement a new dataset.

Usually we recommend to use the first two methods which are usually easier than the third.

In this tutorial, we gives an example that converting the data into the format of existing datasets like COCO, VOC, etc. Other methods and more advanced usages can be found in the [doc](https://mmdetection.readthedocs.io/en/latest/tutorials/new_dataset.html#).

Firstly, let's download a tiny dataset obtained from [KITTI](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d). We select the first 75 images and their annotations from the 3D object detection dataset (it is the same dataset as the 2D object detection dataset but has 3D annotations). We convert the original images from PNG to JPEG format with 80% quality to reduce the size of dataset.
"""

# download, decompress the data
!wget https://mmdatasets.s3-ap-southeast-1.amazonaws.com/datasets.zip
!unzip datasets.zip > /dev/null

# Commented out IPython magic to ensure Python compatibility.
# %cd mmdetection

# Check the directory structure of the tiny data

# Install tree first
!apt-get -q install tree
!tree datasets

# Let's take a look at the dataset image
import mmcv
import matplotlib.pyplot as plt

img = mmcv.imread('datasets/training/image_2/095.jpg')
plt.figure(figsize=(15, 10))
plt.imshow(mmcv.bgr2rgb(img))
plt.show()

"""After downloading the data, we need to implement a function to convert the kitti annotation format into the middle format. In this tutorial we choose to convert them in **`load_annotations`** function in a newly implemented **`KittiTinyDataset`**.

Let's take a loot at the annotation txt file.


"""

# Check the label of a single image
!cat datasets/training/label_2/001.txt

import copy
import os.path as osp

import mmcv
import numpy as np

from mmdet.datasets.builder import DATASETS
from mmdet.datasets.custom import CustomDataset

@DATASETS.register_module()
class channeldataset(CustomDataset):

    CLASSES = ('mainchannel','oxbowlake')

    def load_annotations(self, ann_file):
        cat2label = {k: i for i, k in enumerate(self.CLASSES)}
        # load image list from file
        image_list = mmcv.list_from_file(self.ann_file)
    
        data_infos = []
        # convert annotations to middle format
        for image_id in image_list:
            filename = f'{self.img_prefix}/{image_id}.jpg'
            image = mmcv.imread(filename)
            height, width = image.shape[:2]
    
            data_info = dict(filename=f'{image_id}.jpg', width=width, height=height)
    
            # load annotations
            label_prefix = self.img_prefix.replace('image_2', 'label_2')
            lines = mmcv.list_from_file(osp.join(label_prefix, f'{image_id}.txt'))
    
            content = [line.strip().split(' ') for line in lines]
            bbox_names = [x[0] for x in content]
            bboxes = [[float(info) for info in x[4:8]] for x in content]
    
            gt_bboxes = []
            gt_labels = []
            gt_bboxes_ignore = []
            gt_labels_ignore = []
    
            # filter 'DontCare'
            for bbox_name, bbox in zip(bbox_names, bboxes):
                if bbox_name in cat2label:
                    gt_labels.append(cat2label[bbox_name])
                    gt_bboxes.append(bbox)
                else:
                    gt_labels_ignore.append(-1)
                    gt_bboxes_ignore.append(bbox)

            data_anno = dict(
                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),
                labels=np.array(gt_labels, dtype=np.long),
                bboxes_ignore=np.array(gt_bboxes_ignore,
                                       dtype=np.float32).reshape(-1, 4),
                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))

            data_info.update(ann=data_anno)
            data_infos.append(data_info)

        return data_infos

"""### Modify the config

In the next step, we need to modify the config for the training.
To accelerate the process, we finetune a detector using a pre-trained detector.
"""

from mmcv import Config
# cfg = Config.fromfile('./configs/retinanet/retinanet_r50_caffe_fpn_mstrain_3x_coco.py')
# cfg = Config.fromfile('./configs/yolo/yolov3_d53_mstrain-608_273e_coco.py')
cfg = Config.fromfile('./configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco.py')

"""Given a config that trains a Faster R-CNN on COCO dataset, we need to modify some values to use it for training Faster R-CNN on KITTI dataset."""

from mmdet.apis import set_random_seed

# Modify dataset type and path
# Modify dataset type and path
cfg.dataset_type = 'channeldataset'
cfg.data_root = 'datasets/'

cfg.data.test.type = 'channeldataset'
cfg.data.test.data_root = 'datasets/'
cfg.data.test.ann_file = 'train.txt'
cfg.data.test.img_prefix = 'training/image_2'

cfg.data.train.type = 'channeldataset'
cfg.data.train.data_root = 'datasets/'
cfg.data.train.ann_file = 'train.txt'
cfg.data.train.img_prefix = 'training/image_2'

cfg.data.val.type = 'channeldataset'
cfg.data.val.data_root = 'datasets/'
cfg.data.val.ann_file = 'val.txt'
cfg.data.val.img_prefix = 'training/image_2'

# modify num classes of the model in box head
cfg.model.roi_head.bbox_head.num_classes = 2
# cfg.model.bbox_head.num_classes = 2
# We can still use the pre-trained Mask RCNN model though we do not need to
# use the mask branch
cfg.load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'

# Set up working dir to save files and logs.
cfg.work_dir = './tutorial_exps'

# The original learning rate (LR) is set for 8-GPU training.
# We divide it by 8 since we only use one GPU.
cfg.optimizer.lr = 0.0025
cfg.lr_config.warmup = None
cfg.log_config.interval = 40
cfg.runner.max_epochs = 50
# Change the evaluation metric since we use customized dataset.
cfg.evaluation.metric = 'mAP'
# We can set the evaluation interval to reduce the evaluation times
cfg.evaluation.interval = 1
# We can set the checkpoint saving interval to reduce the storage cost
cfg.checkpoint_config.interval = 20

# Set seed thus the results are more reproducible
cfg.seed = 0
set_random_seed(0, deterministic=False)
cfg.gpu_ids = range(1)


# We can initialize the logger for training and have a look
# at the final config used for training
print(f'Config:\n{cfg.pretty_text}')

"""### Train a new detector

Finally, lets initialize the dataset and detector, then train a new detector!
"""

from mmdet.datasets import build_dataset
from mmdet.models import build_detector
from mmdet.apis import train_detector


# Build dataset
datasets = [build_dataset(cfg.data.train)]

# Build the detector
model = build_detector(
    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))
# Add an attribute for visualization convenience
model.CLASSES = datasets[0].CLASSES

# Create work_dir
mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))
train_detector(model, datasets, cfg, distributed=False, validate=True)

"""### Understand the log
From the log, we can have a basic understanding the training process and know how well the detector is trained.

Firstly, the ResNet-50 backbone pre-trained on ImageNet is loaded, this is a common practice since training from scratch is more cost. The log shows that all the weights of the ResNet-50 backbone are loaded except the `conv1.bias`, which has been merged into `conv.weights`.

Second, since the dataset we are using is small, we loaded a Mask R-CNN model and finetune it for detection. Because the detector we actually using is Faster R-CNN, the weights in mask branch, e.g. `roi_head.mask_head`, are `unexpected key in source state_dict` and not loaded.
The original Mask R-CNN is trained on COCO dataset which contains 80 classes but KITTI Tiny dataset only have 3 classes. Therefore, the last FC layer of the pre-trained Mask R-CNN for classification has different weight shape and is not used.

Third, after training, the detector is evaluated by the default VOC-style evaluation. The results show that the detector achieves 54.1 mAP on the val dataset,
 not bad!

## Test the trained detector

After finetuning the detector, let's visualize the prediction results!
"""

!python tools/model_converters/publish_model.py /content/mmdetection/tutorial_exps/latest.pth faster_rcnn_r50_fpn_3x_v9.pth

from mmdet.apis import inference_detector, init_detector, show_result_pyplot
import mmcv

img = mmcv.imread('/content/drive/MyDrive/testsetv2/test009.jpg')

model.cfg = cfg
result = inference_detector(model, img)
show_result_pyplot(model, img, result, score_thr=0.9)

"""### Download all training result"""

import os

# !mkdir output

directory = r'datasets/training/image_2/'
# directory = r'testset/'
for filename in os.listdir(directory):

  img = mmcv.imread(directory+filename)

  model.cfg = cfg
  result = inference_detector(model, img)
  model.show_result(img, result, out_file='output/%s'%filename, score_thr= 0.9)
  # model.show_result(img)

"""###Plot loss"""

!python /content/mmdetection/tools/analysis_tools/analyze_logs.py plot_curve /content/mmdetection/tutorial_exps/Fasterrcnn_resnet50_40epch.log.json --keys loss_cls loss_bbox --legend loss_cls loss_bbox --out losses_lr0.0025_40epch.pdf

"""### Export bbox coordinate to csv"""

import pandas as pd

# initialize datafram
df = pd.DataFrame({"pic":[],"class":[],"num":[],"ymax":[],"ymin":[],"xmax":[],"xmin":[],"prob":[]})
# df_oxbow = pd.DataFrame({"num":[],"ymax":[],"ymin":[],"xmax":[],"xmin":[],"prob":[]})
df

import os



# directory = r'datasets/training/image_2/'
directory = r'/content/drive/MyDrive/testsetv2/'
for filename in os.listdir(directory):

  img = mmcv.imread(directory+filename)

  model.cfg = cfg
  result = inference_detector(model, img)
  # print(result)
  # print("*****************************")
  i=1
  for r in result[0]:      # main_channel
    if r[4] > 0.9:
  #     # print(r)
  #     # print("****************************")
  #   # for i in r:
      r = np.reshape(r,[1,5])
      listofdata = np.array([filename,"main_channel",i])
      listofdata = np.append(listofdata,r)
      listofdata = np.reshape(listofdata,[1,8])
      df_test = pd.DataFrame(listofdata, columns =df.columns)
      df = df.append(df_test, ignore_index=True)   
    i+=1
  i=1    
  for r in result[1]:    # oxbow_lake
    if r[4] > 0.9:
      r = np.reshape(r,[1,5])
      listofdata = np.array([filename,"oxbow_lake",i])
      listofdata = np.append(listofdata,r)
      listofdata = np.reshape(listofdata,[1,8])
      df_test = pd.DataFrame(listofdata, columns =df.columns)
      df = df.append(df_test, ignore_index=True)   
    i+=1

df

df.to_csv('test_lr0.0025_thr0.9_v9.csv', index=False)

!rm -rf /content/mmdetection/output

# import matplotlib.pyplot as plt
# import matplotlib.image as mpimg
# !mkdir imgwithaxis
# directory = r'datasets/training/image_2/'
# for filename in os.listdir(directory):

#   image=mpimg.imread(directory+filename)
#   imgplot = plt.imshow(image)
#   plt.savefig("/content/mmdetection/imgwithaxis/%s"%filename,pad = 0, format="jpg")

from mmdet.apis import inference_detector, init_detector, show_result_pyplot

# Choose to use a config and initialize the detector
config = '/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco.py'
# Setup a checkpoint file to load
checkpoint = '/content/mmdetection/faster_rcnn_r50_fpn_3x_v9-d5c7015e.pth'
# initialize the detector
model = init_detector(config, checkpoint, device='cuda:0')

img = '/content/test006.jpg'
result = inference_detector(model, img)

# Let's plot the result
show_result_pyplot(model, img, result, score_thr=0.1)

from google.colab import drive
drive.mount('/content/drive')